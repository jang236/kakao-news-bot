import os
import re
import google.generativeai as genai
from fastapi import FastAPI
from pydantic import BaseModel
import requests
from bs4 import BeautifulSoup

# ===== Gemini API ì„¤ì • =====
API_KEY = os.environ.get("GEMINI_API_KEY", "")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë‰´ìŠ¤ë¥¼ ê²½ì œì  ê´€ì ì—ì„œ í•´ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ê·œì¹™]
- ëª¨ë“  ë¶„ì•¼ì˜ ë‰´ìŠ¤(ì •ì¹˜, ì‚¬íšŒ, ê¸°ìˆ , êµ­ì œ ë“±)ë¥¼ ë°›ë˜, ê²½ì œ/íˆ¬ìì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„
- ì…ë ¥ëœ ë‰´ìŠ¤ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ 3íšŒ ì••ì¶•: íˆ¬ì ê´€ë ¨ í•„í„°ë§ â†’ ì¸ê³¼ê´€ê³„ êµ¬ì¡°í™” â†’ í•µì‹¬ íŒë‹¨ ìš”ì†Œ ì¶”ì¶œ. ì´ ê³¼ì •ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
- ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì‰¬ìš´ ì„¤ëª… (ì˜ˆ: ê¸°ì¤€ê¸ˆë¦¬(í•œêµ­ì€í–‰ì´ ì •í•˜ëŠ” ì´ììœ¨ ê¸°ì¤€))
- ì¹œê·¼í•œ ë§íˆ¬ (~ê±°ë“ ìš”, ~ë€ ë§ì´ì—ìš”, ~ê±°ì˜ˆìš”)
- í™•ì •ì  í‘œí˜„ ê¸ˆì§€, ê°€ëŠ¥ì„±ìœ¼ë¡œ í‘œí˜„
- ë§ˆí¬ë‹¤ìš´(**, *, -, ë²ˆí˜¸ ëª©ë¡ ë“±) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€. ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
- ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ì´ë¯€ë¡œ ìµœëŒ€í•œ ì§§ê²Œ ì‘ì„±
- ê° ì„¹ì…˜ ì‚¬ì´ì— ë¹ˆ ì¤„ì„ ë„£ì–´ ë¬¸ë‹¨ì„ ëª…í™•íˆ êµ¬ë¶„

[ì¶œë ¥ í˜•ì‹ â€” ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ]

ğŸ“° (ê¸°ì‚¬ ì›ë¬¸ ì œëª© ê·¸ëŒ€ë¡œ)

âœ… ìš”ì•½ (ğŸŸ¢ê¸ì • / ğŸ”´ë¶€ì • / ğŸŸ¡ì¤‘ë¦½):
í•µì‹¬ ë‚´ìš© 3~4ë¬¸ì¥. ëˆ„ê°€ ë¬´ì—‡ì„ ì™œ í–ˆëŠ”ì§€, ê²½ì œ/ì‹œì¥ì— ì–´ë–¤ ì˜í–¥ì¸ì§€.

ğŸ’¡ ì‰¬ìš´ í•´ì„:
ì™œ ì¤‘ìš”í•œì§€ 1~2ë¬¸ì¥ë§Œ. ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ.

ğŸ·ï¸ ê´€ë ¨ ì„¹í„°: (ì˜í–¥ ë°›ëŠ” ì‚°ì—…/ì„¹í„° ë‚˜ì—´)

ğŸ¤– ì½”ë©˜íŠ¸: (ì„íŒ©íŠ¸ ìˆëŠ” í•œì¤„ ì½”ë©˜íŠ¸. ì§§ê³  ê°•ë ¬í•˜ê²Œ.)

[ì˜ˆì™¸ ì²˜ë¦¬]
- ë‰´ìŠ¤ê°€ ì•„ë‹Œ ë‚´ìš©ì´ ì…ë ¥ëœ ê²½ìš°: "ë‰´ìŠ¤ ê¸°ì‚¬ URLì„ ë„£ì–´ì£¼ì‹œë©´ ë¶„ì„í•´ë“œë¦´ê²Œìš”!"
- ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì€ ê²½ìš°: "ê¸°ì‚¬ ë‚´ìš©ì´ ë¶€ì¡±í•´ìš”. ë‹¤ë¥¸ ê¸°ì‚¬ë¥¼ ë„£ì–´ì£¼ì‹œë©´ ë¶„ì„í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”!"

ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""

app = FastAPI()


class Message(BaseModel):
    text: str


def extract_article_text(url: str) -> str:
    """URLì—ì„œ ê¸°ì‚¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                       "AppleWebKit/537.36 (KHTML, like Gecko) "
                       "Chrome/120.0.0.0 Safari/537.36"
    }
    resp = requests.get(url, headers=headers, timeout=10)
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
    for tag in soup(["script", "style", "nav", "header", "footer", "aside", "iframe"]):
        tag.decompose()

    # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì¶”ì¶œ
    article = soup.select_one("#dic_area, #articleBodyContents, .article_body, "
                               "article, .news_end, #articeBody, #newsEndContents")
    if article:
        text = article.get_text(strip=True, separator="\n")
    else:
        text = soup.get_text(strip=True, separator="\n")

    # ë¹ˆ ì¤„ ì •ë¦¬ ë° ê¸¸ì´ ì œí•œ
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    return "\n".join(lines)[:4000]


def is_url(text: str) -> bool:
    """í…ìŠ¤íŠ¸ê°€ URLì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return bool(re.match(r"https?://", text.strip()))


def analyze_news(url: str) -> str:
    """ë‰´ìŠ¤ URLì„ í¬ë¡¤ë§í•˜ê³  Geminië¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        article_text = extract_article_text(url)
        if len(article_text) < 50:
            return "âš ï¸ ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        prompt = f"{SYSTEM_PROMPT}\n\n---\nê¸°ì‚¬ ë³¸ë¬¸:\n{article_text}"
        response = model.generate_content(prompt)
        return response.text

    except requests.exceptions.Timeout:
        return "âš ï¸ ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    except requests.exceptions.RequestException as e:
        return f"âš ï¸ URL ì ‘ì† ì˜¤ë¥˜: {str(e)}"
    except Exception as e:
        return f"âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"


@app.get("/")
async def root():
    return {"status": "ok", "message": "ë‰´ìŠ¤ ë¶„ì„ ë´‡ ì„œë²„ ì‘ë™ ì¤‘"}


@app.post("/analyze")
async def analyze(msg: Message):
    text = msg.text.strip()

    # "ë¶„ì„" í‚¤ì›Œë“œ ì œê±°
    if text.startswith("ë¶„ì„ "):
        text = text.replace("ë¶„ì„ ", "", 1).strip()

    if not is_url(text):
        return {"response": "âš ï¸ ì˜¬ë°”ë¥¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\nì‚¬ìš©ë²•: ë¶„ì„ https://ë‰´ìŠ¤URL"}

    result = analyze_news(text)
    return {"response": result}


@app.get("/health")
async def health():
    return {"status": "ok"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
