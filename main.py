import os
import re
import google.generativeai as genai
from fastapi import FastAPI
from pydantic import BaseModel
import requests
from bs4 import BeautifulSoup

# ===== Gemini API ì„¤ì • =====
API_KEY = os.environ.get("GEMINI_API_KEY", "")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ê¸°ì‚¬ ë³¸ë¬¸ì„ ì½ê³  ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ğŸ“° ê¸°ì‚¬ ìš”ì•½
â€¢ ì œëª©: (ê¸°ì‚¬ ì œëª©)
â€¢ í•µì‹¬: (1~2ì¤„ í•µì‹¬ ë‚´ìš©)
â€¢ ë°°ê²½: (ì™œ ì´ ë‰´ìŠ¤ê°€ ë‚˜ì™”ëŠ”ì§€)
â€¢ ì˜í–¥: (ì–´ë–¤ ì˜í–¥ì´ ì˜ˆìƒë˜ëŠ”ì§€)
â€¢ í•œì¤„í‰: (í•œ ì¤„ë¡œ ì •ë¦¬)

ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""

app = FastAPI()


class Message(BaseModel):
    text: str


def extract_article_text(url: str) -> str:
    """URLì—ì„œ ê¸°ì‚¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                       "AppleWebKit/537.36 (KHTML, like Gecko) "
                       "Chrome/120.0.0.0 Safari/537.36"
    }
    resp = requests.get(url, headers=headers, timeout=10)
    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
    for tag in soup(["script", "style", "nav", "header", "footer", "aside", "iframe"]):
        tag.decompose()

    # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì¶”ì¶œ
    article = soup.select_one("#dic_area, #articleBodyContents, .article_body, "
                               "article, .news_end, #articeBody, #newsEndContents")
    if article:
        text = article.get_text(strip=True, separator="\n")
    else:
        text = soup.get_text(strip=True, separator="\n")

    # ë¹ˆ ì¤„ ì •ë¦¬ ë° ê¸¸ì´ ì œí•œ
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    return "\n".join(lines)[:4000]


def is_url(text: str) -> bool:
    """í…ìŠ¤íŠ¸ê°€ URLì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return bool(re.match(r"https?://", text.strip()))


def analyze_news(url: str) -> str:
    """ë‰´ìŠ¤ URLì„ í¬ë¡¤ë§í•˜ê³  Geminië¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        article_text = extract_article_text(url)
        if len(article_text) < 50:
            return "âš ï¸ ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        prompt = f"{SYSTEM_PROMPT}\n\n---\nê¸°ì‚¬ ë³¸ë¬¸:\n{article_text}"
        response = model.generate_content(prompt)
        return response.text

    except requests.exceptions.Timeout:
        return "âš ï¸ ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    except requests.exceptions.RequestException as e:
        return f"âš ï¸ URL ì ‘ì† ì˜¤ë¥˜: {str(e)}"
    except Exception as e:
        return f"âš ï¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"


@app.get("/")
async def root():
    return {"status": "ok", "message": "ë‰´ìŠ¤ ë¶„ì„ ë´‡ ì„œë²„ ì‘ë™ ì¤‘"}


@app.post("/analyze")
async def analyze(msg: Message):
    text = msg.text.strip()

    # "ë¶„ì„" í‚¤ì›Œë“œ ì œê±°
    if text.startswith("ë¶„ì„ "):
        text = text.replace("ë¶„ì„ ", "", 1).strip()

    if not is_url(text):
        return {"response": "âš ï¸ ì˜¬ë°”ë¥¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\nì‚¬ìš©ë²•: ë¶„ì„ https://ë‰´ìŠ¤URL"}

    result = analyze_news(text)
    return {"response": result}


@app.get("/health")
async def health():
    return {"status": "ok"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
